name: Sync and Run Ollama Server
on:
  push:
    branches: [main]

  workflow_dispatch:

jobs:
  sync-to-hub:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          lfs: true  # If using Large File Storage

      - name: Install Dependencies
        run: |
          sudo apt update
          sudo apt install -y curl

      - name: Download and Install Ollama
        run: |
          curl -fsSL https://ollama.ai/install.sh | sh

      - name: Start Ollama Server
        run: |
          nohup ollama serve > ollama.log 2>&1 &

      - name: Run Streamlit App
        env:
          HF_USERNAME: ${{ secrets.HF_USERNAME }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          streamlit run app.py --server.port 8501 --server.headless true
